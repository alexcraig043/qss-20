{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7edf036",
   "metadata": {},
   "source": [
    "# 1. Problem Set 2: Data manipulation with `pandas`\n",
    "\n",
    "**Total points**: 53\n",
    "\n",
    "By investigating disparities in sentencing between black defendants and white defendants, this problem set will give you practice with:\n",
    "\n",
    "- Data wrangling with pandas: groupby, subsetting, sorting, etc.\n",
    "- Defining your own functions\n",
    "- Visualizing trends in data\n",
    "\n",
    "We will use the Cook County, Illinois (which contains Chicago) sentencing dataset. This analysis could be extended to study Hispanic defendants or, in a different jurisdiction, Asian and other minoritized groups.\n",
    "\n",
    "This dataset reports the sentence given to defendants convicted of different crimes, and you can find [the data codebook here](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf) and the latest on these data [at the official website](https://datacatalog.cookcountyil.gov/Courts/Sentencing/tg8v-tm6u).\n",
    "\n",
    "**Details if interested in digging deeper** (optional): There is a lot to think about here in terms of (1) how we might measure disparities, and (2) what factors you would want to adjust for when deciding whether two defendants are 'similarly situated' but for their race. You can read more technical coverage in the following sources:\n",
    "\n",
    "- [Review of sentencing disparities research](https://www.journals.uchicago.edu/doi/full/10.1086/701505)\n",
    "- [Discussion of causal model/blinding race at charging stage of the prosecutorial process](https://5harad.com/papers/blind-charging.pdf)\n",
    "- [Discussion of measuring discrimination in policing that can generalize to the sentencing case](https://www.annualreviews.org/doi/abs/10.1146/annurev-criminol-011518-024731)\n",
    "- [General discussion of causal challenges in measuring between-group disparities](https://osf.io/preprints/socarxiv/gx4y3/)\n",
    "\n",
    "**One major caveat**: when comparing whether two similar defendants received different sentences, we're missing one important attribute that influences sentencing: the defendant's criminal history. This influences sentencing both through sentencing guidelines, which can prescribe longer sentences for those who have certain types of prior convictions, and through judicial discretion if judges are more lenient with first-time defendants. The above sources discuss how much we want to \"control away\" for this prior history, since if we think there are racial biases in which defendants, conditional on *committing* a crime, are arrested and charged, we may not want to adjust for that factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932aa32",
   "metadata": {},
   "source": [
    "# 0. Load packages and imports (2 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## for plotting; can also use matplotlib or seaborn\n",
    "## note: for plotnine, you likely need to install using pip or conda\n",
    "## if not using plotnine for viz, no need to import it (can comment out next two lines)\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## datetime util\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cc59a",
   "metadata": {},
   "source": [
    "## 0.1 Load the raw data (1 point)\n",
    "\n",
    "Use `pd.read_csv` to load the `sentencing_asof0405.csv` data. To get this, unzip `pset2_inputdata.zip` (try the `unzip` shell command). Be sure to use relative path names (e.g., `../data/file.csv` goes up a level and looks inside the `data/` folder for `file.csv`) and **don't hard code** your user-specific path name (e.g., `C:/files/data/file.csv`). If you can't find the file,  double-check you're looking in the right directory (the `os` library in Python can help with this).\n",
    "\n",
    "*Notes*: You may receive a warning about mixed data types upon import; feel free to ignore, or call `low_memory=False` as a parameter.\n",
    "\n",
    "**Hint:**\n",
    "You may receive a warning about mixed data types upon loading the .csv file into pandas; feel free to ignore, or call `low_memory=False` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5aef8",
   "metadata": {},
   "source": [
    "## 0.2 Inspect the data (1 points)\n",
    "\n",
    "Print the head, dimensions, and info for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df454475",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a101f84",
   "metadata": {},
   "source": [
    "# 1. Data cleaning/interpretation (21 points total)\n",
    "\n",
    "## 1.1: Understanding the unit of analysis (5 points)\n",
    "\n",
    "\n",
    "### 1.1.1 Print the number of unique values for the following columns all at once (e.g., with `.apply()`), i.e. without copying/pasting code to do each one separately:\n",
    "\n",
    "- Cases (CASE_ID)\n",
    "- People (CASE_PARTICIPANT_ID)\n",
    "- Charges (CHARGE_ID)\n",
    "\n",
    "**Source for this question**: [slide 30 here on column-wise apply](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing numbers of unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66df450",
   "metadata": {},
   "source": [
    "### 1.1.2  Cases and people\n",
    "\n",
    "You might have noticed there are more unique people than unique cases and more unique charges than unique people. This is because the same case can have multiple people involved, and the same person can have multiple charges tied to a case. Illustrate this by showing:\n",
    "   \n",
    "- an example of a case involving multiple people\n",
    "- an example of a person in a case involving multiple charges\n",
    "\n",
    "**Resources**: groupby and agg covered in:\n",
    "- [The in-class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_pandas_blank.ipynb) and [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb)\n",
    "\n",
    "- [These lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391fd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here showing a case with multiple people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee995398",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here showing a case with multiple charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72267baa",
   "metadata": {},
   "source": [
    "### 1.1.3 Finding mean and median \n",
    "\n",
    "- Print the mean and median number of charges per `CASE_PARTICIPANT_ID`\n",
    "- Print the mean and median number of participants per `CASE_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64221056",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here finding mean and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676d512",
   "metadata": {},
   "source": [
    "### 1.1.4 Does the data enable us to follow the same defendant across different cases they're charged in? Write 1 sentence in support of your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6de563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here checking for linkage of people across cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19ad2",
   "metadata": {},
   "source": [
    "(your text response here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b79087",
   "metadata": {},
   "source": [
    "## 1.2 Which offense is final? (3 points)\n",
    "\n",
    "First, read the data documentation ([link here](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf)) and summarize in your own words the differences between `OFFENSE_CATEGORY` and `UPDATED_OFFENSE_CATEGORY`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ac835",
   "metadata": {},
   "source": [
    "(your text response here summarizing the differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fb7a6",
   "metadata": {},
   "source": [
    "Then construct an indicator `is_changed_offense` that's True for case-participant-charge observations (rows) where there's a difference between the `OFFENSE_CATEGORY` and the `UPDATED_OFFENSE_CATEGORY`. \n",
    "\n",
    "**Resources**: row subsetting, groupby/agg, and np.where covered in [lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here constructing indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92037678",
   "metadata": {},
   "source": [
    "What are some of the more common changed offenses? Consider both:\n",
    "  - The raw number of changed offenses that come from each `OFFENSE_CATEGORY` (e.g., using `value_counts()`). This should answer the question: What offenses contribute the most to the pool of changed offenses?\n",
    "  - The proportion of each `OFFENSE_CATEGORY` that gets changed (can just compute mean and print result of `sort_values()`). This should answer the question: What offenses tend to get changed the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af192301",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here inspecting most common changed offenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23691bbc",
   "metadata": {},
   "source": [
    "Print one example of a changed offense from one of these categories and comment on what the reason may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb36a7",
   "metadata": {},
   "source": [
    "## 1.3 Simplifying the charges (5 points)\n",
    "\n",
    "Using the field (`UPDATED_OFFENSE_CATEGORY`), create a new field, `simplified_offense_derived`, that simplifies the many offense categories into broader buckets using the following process:\n",
    "\n",
    "First, create a new variable that strips \"Aggravated\" (capitalized) from the `UPDATED_OFFENSE_CATEGORY` (e.g., 'Aggravated Battery' just becomes 'Battery', 'Aggravated DUI' becomes 'DUI')\n",
    "\n",
    "**Resources**: slide 35 of [the lecture on data wrangling with pandas](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf) has str.replace (example with stripping the name \"Johnson\" from a last name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here stripping 'Aggravated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889e6ab",
   "metadata": {},
   "source": [
    "Then:\n",
    "- Combine all offenses with 'Arson' in the string into a single `Arson` category\n",
    "- Combine all offenses with 'Homicide' in the string into a single `Homicide` category\n",
    "- Combine all offenses with 'Vehic' in the string into a single `Vehicle-related` category\n",
    "- Combine all offenses with 'Battery' in the string into a single `Battery` category\n",
    "- Use the simplified offense variable created above (the one without 'Aggravated') as the fallback/default value (instead of 'other')\n",
    "\n",
    "Do so efficiently, using `np.select()` (or a similar procedure for systematic recoding) rather than separate line for each recoded offense.\n",
    "\n",
    "**Resources**:\n",
    "- [Activity code](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb) and [lecture on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/01_qss20_w23_pandas.pdf) covers `np.select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18720b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here combining offenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8918053",
   "metadata": {},
   "source": [
    "Print the difference between the # of unique offenses in the original `UPDATED_OFFENSE_CATEGORY` field and the # of unique offenses in your new `simplified_offense_derived` field. How many and which ones change?\n",
    "\n",
    "*Hint*: You can turn unique values from a column into a list using `df[col].unique().tolist()` and get the difference between two lists using a list comprehension: `[elem for elem in list1 if elem not in list2]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here printing differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b6c6d",
   "metadata": {},
   "source": [
    "## 1.4: Cleaning sentencing date (3 points)\n",
    "Create `sentenceymd_derived` that's a version of `SENTENCING_DATE` converted to datetime format. Also create a rounded version, `sentenceym_derived`, that's rounded down to the first of the month and the year (e.g., 01-05-2016 and 01-27-2016 each become 01-01-2016). \n",
    "\n",
    "*Hints*: All timestamps are midnight so you can strip the timestamp. Before converting, you'll notice that some of the years have been mistranscribed (e.g., 291X or 221X instead of 201X). Programatically fix those (eg 2914 -> 2014). You can use this regex code to clean the dates or write your own pattern: ### first, use regex to clean up the date columns\n",
    "\n",
    "```python\n",
    "sentence['tmp_clnsdate'] = [re.sub(r'2[1-9]([0-9]+)', r\"20\\1\", str(date)) \n",
    "                            if bool(re.search('\\/2[1-9][0-9]+', str(date))) else \n",
    "                            str(date) \n",
    "                            for date in \n",
    "                            sentence.SENTENCE_DATE]\n",
    "```\n",
    "\n",
    "Even after cleaning, there will still be some that are after the year 2021 that we'll filter out later.\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- pd.to_datetime() used in [the data wrangling activity](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb)\n",
    "- extract the month and year from a datetime object using the dt accessor (similar syntax for year): https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here that creates datetime version of sentencing date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0dac2",
   "metadata": {},
   "source": [
    "## 1.5 Subsetting rows to analytic dataset (5 points)\n",
    "\n",
    "Let's narrow down the above sentencing dataset in a few ways. First, subset to cases where only one participant is charged, since cases with >1 participant might have complications like plea bargains/informing from other participants affecting the sentencing of the focal participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad49d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to limit to one participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c509da",
   "metadata": {},
   "source": [
    "Next, let's go from a participant-case level dataset, where each participant is repeated across charges tied to the case, to a participant-level dataset, where each participant has one charge. To do this, let's subset to a participant's primary charge and their current sentence (`PRIMARY_CHARGE_FLAG` is True and `CURRENT_SENTENCE_FLAG` is True). Double check that this worked by confirming there are no longer multiple charges for the same case-participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to subset to primary charge and current sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b7739",
   "metadata": {},
   "source": [
    "Finally, apply these two additional filters: \n",
    "\n",
    "- filter out observations where judge is nan or nonsensical (indicated by `is.null` or equal to `FLOOD`)\n",
    "- subset to sentencing date between `01-01-2012` and `04-05-2021` (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to apply remaining filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adedc32d",
   "metadata": {},
   "source": [
    "# 2. Investigating Black vs. White sentencing disparities (30 points total)\n",
    "\n",
    "## 2.0 Load the cleaned data (1 point)\n",
    "Use `pd.read_csv` to load the `sentencing_cleaned.csv` data. This file is included in the same zip file you used for part 1 above. You'll notice the data is slightly different from what we used for part 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e73bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce0f3b",
   "metadata": {},
   "source": [
    "## 2.1. Investigating one type of between-group difference: who reaches the sentencing stage? (8 points)\n",
    "\n",
    "Calculate the fraction of Black versus White defendants by month and year:\n",
    "\n",
    "- Denominator is number of unique cases that month\n",
    "- Numerator for black defendants is count of `is_black_derived`\n",
    "- Numerator for white defendants is count of `is_white_derived`\n",
    "- Fraction of each is numerator/denominator\n",
    "\n",
    "**Hint:**\n",
    "For this and other time-based questions in this pset, you can use either `sentenceymd_derived` or `sentenceym_derived` (whichever makes more sense for the question). As a reminder, `sentenceymd_derived` is a version of `SENTENCING_DATE` converted to datetime format, and `sentenceym_derived` is a version rounded down to the first of the month and the year (e.g., 01-05-2016 and 01-27-2016 each become 01-01-2016).\n",
    "\n",
    "**Concepts tested and resources**:\n",
    "- Groupby and agg, as covered in [these lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/01_qss20_w23_pandas.pdf), [the class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_pandas_blank.ipynb) and its [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb), and [the DataCamp on Data Manipulation with Pandas](https://app.datacamp.com/learn/courses/data-manipulation-with-pandas)\n",
    "\n",
    "- List comprehension (one option), as covered in [these lecture slides on lists & functions](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/02_qss20_w23_pythonbasics.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94846d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f12ad",
   "metadata": {},
   "source": [
    "- With that calculation, create a graph with two lines: one for Black defendants as fraction of total; another for White defendants. Make sure it includes a legend summarizing which color is for which group, and clean the legend so that it has informative names (e.g., Black or White rather than prop_black or prop_white).\n",
    "- Use mathematical notation to write out each of the proportions using summation notation in a 1-2 sentence writeup describing trends. What seems to be going on in April and May 2020? \n",
    "\n",
    "**Optional challenge** (no extra credit points): improve the viz by shading the background of the visualization for months with fewer than 100 cases \n",
    "\n",
    "**Optional challenge** (no extra credit points): improve the viz by adding a vertical line for 12-01-2016, the month that new State's Attorney Foxx took office \n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- Access mathematical notation in Jupyter notebooks with the dollar sign (`$`) special character and commands like `\\dfrac{Numerator}{Denominator}` and `\\sum_{start}^{end}`, e.g.: \n",
    "$\\dfrac{\\sum_{i}^{N} One thing}{\\sum_{i}^{N} Another thing}$\n",
    "\n",
    "**Concepts tested and resources:** \n",
    "\n",
    "- Visualization, as covered in [this plotnine example code](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_plotting_examples_plotnine.ipynb), chapter 4 of [the DataCamp course on Data Manipulation with Pandas](https://app.datacamp.com/learn/courses/data-manipulation-with-pandas), and the optional DataCamp courses on Data Visualization with ggplot2/Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b6481",
   "metadata": {},
   "source": [
    "(Your interpretation here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a08866",
   "metadata": {},
   "source": [
    "## 2.2.0 Investigating mechanisms: incarceration rates by charge (21 points total)\n",
    "\n",
    "Your colleague sees the previous graph and is worried that the gap could be different---either wider or smaller---if you adjust for the fact that prosecutors have discretion in what crimes to charge defendants with. If white defendants are charged with crimes that tend to receive probation rather than incarceration, that could explain some of the gaps.\n",
    "\n",
    "In the next questions, you'll begin to investigate this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f88ca",
   "metadata": {},
   "source": [
    "### 2.2.1 Find the most common offenses (3 points)\n",
    "\n",
    "First, based on `simplified_offense_derived`, create a set of 'frequent offenses' that represent (over the entire period) the union of the 10 offenses Black defendant are most likely to be charged with and the 10 offenses white defendants are most likely to be charged with (might be far less than 20 total if there's a lot of overlap in common charges)\n",
    "\n",
    "**Hint:** To get the unique elements of a list (i.e., remove overlaps), create a `set()`, which only stores unique values (syntax slightly different than with lists).\n",
    "\n",
    "**Concepts tested and resources:**\n",
    "\n",
    "- Row subsetting and sorting, as covered in [these lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf), [the class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_pandas_blank.ipynb) and its [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb), and [the DataCamp on Data Manipulation with Pandas](https://app.datacamp.com/learn/courses/data-manipulation-with-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba268d9d",
   "metadata": {},
   "source": [
    "### 2.2.2 Look at incarceration rates (whether incarcerated) by race and offense type for these top offenses (3 points)\n",
    "\n",
    "Print a wide-format version of the resulting table (so each row is an offense type, one column is black incarceration rate for that offense type, and another column is the white incarceration rate) and interpret. What offenses show the largest disparities in judges being less likely to sentence White defendants to incarceration/more likely to offer those defendants probation?\n",
    "\n",
    "According to the codebook, incarceration is indicated by `COMMITMENT_TYPE` == \"Illinois Department of Corrections\".\n",
    "\n",
    "**Hint:** To create a wide-format version of a table, one option is [`pd.pivot_table()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html). \n",
    "\n",
    "**Concepts tested and resources:**\n",
    "\n",
    "- Recoding columns using logical conditions (e.g., with np.where) and groupby with agg, as covered in [these lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf) and [the class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_pandas_blank.ipynb) and its [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f1f2c",
   "metadata": {},
   "source": [
    "(Your text response here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d714cf2",
   "metadata": {},
   "source": [
    "### 2.2.3 Examine whether this changes pre and post change to charging threshold for retail theft (10 points)\n",
    "\n",
    "One important question is not only whether there are disparities by offense type, but also whether these disparities have changed over time.\n",
    "\n",
    "For instance, the SAO (State Attorney Office) announced in December of 2016 that they would no longer default to charging retail thefts of under \\$1,000 as felonies. This change might have (1) decreased disparities or (2) increased disparities, depending on the correlation between race/ethnicity and magnitude of goods stolen (see [this article](https://www.dnainfo.com/chicago/20161215/little-village/kim-foxx-raises-bar-for-retail-theft-felonies/) for more background). \n",
    "\n",
    "Focusing on `simplified_offense_derived` == \"Retail theft\", write a user-defined function that allows you to efficiently: \n",
    "\n",
    "- Compare Black-White disparities before and after the change using a two-month bandwidth (so pre is October and November 2016; post is January and February 2017)\n",
    "\n",
    "- Compare Black-White disparities before and after the change using a four-month bandwidth (so pre is August- November 2016; post is January - April 2017)\n",
    "\n",
    "- Compare Black-White disparities using an eight-month bandwidth\n",
    "\n",
    "- Compare Black-White disparities using a twelve-month bandwidth\n",
    "\n",
    "In other words, the function should compare percentages of defendants incarcerated for retail theft by race. The numerator in the proportions is the # of defendants incarcerated for retail theft, the denom is # of total defendants for retail theft (calculate this separately for each race and separately for before versus after); disparity is the difference in proportions.\n",
    "\n",
    "Exclude Dec. 2016 as a transition month.\n",
    "\n",
    "------------------ \n",
    "\n",
    "Print a table with the results (any organization is fine as long as it's clear).\n",
    " \n",
    "------------------ \n",
    " \n",
    "**Concepts tested and resources**:\n",
    "    \n",
    "- User-defined functions and list comprehensions, as will be covered in class on 01/18 in [these slides](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/04_qss20_w23_userdefinedfunctions.pdf) and [the functions activity](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/02_functions_blank.ipynb) and [its solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/02_functions_solutions.ipynb) (forthcoming on 01/18)\n",
    "\n",
    "- Row subsetting with logical conditions (e.g., with np.where), as covered in [these lecture slides on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/slides/03_qss20_w23_pandas.pdf) and [the class activity on data wrangling](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_pandas_blank.ipynb) and its [solutions](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/solutions/01_pandas_solutions.ipynb)\n",
    "\n",
    "- Visualization, as covered in [this plotnine example code](https://github.com/jhaber-zz/QSS20_public/blob/main/activities/01_plotting_examples_plotnine.ipynb), chapter 4 of [the DataCamp course on Data Manipulation with Pandas](https://app.datacamp.com/learn/courses/data-manipulation-with-pandas), and the optional DataCamp courses on Data Visualization with ggplot2/Matplotlib\n",
    "\n",
    "**Hints on function:** Your function should take these steps:\n",
    "\n",
    "1. Create a December 2016 object and use that to create a range corresponding to the bandwidth.\n",
    "2. Filter to rows within December 2016 +- that # of months. For example, for the 2-month bandwidth, the \"before\" period is Oct and Nov 2016; after is Jan and Feb 2017. Instead of using timedelta to increment in time (as we did in class function activity), use [**relativedelta**](https://dateutil.readthedocs.io/en/stable/relativedelta.html) to increment in months.\n",
    "3. Within that filtered dataset, examine Black-White disparities in incarceration before versus after. One shortcut for doing this is to keep the full dataframe together and construct an `is_after` indicator (e.g., using `np.where()`) that takes the value of `True` if after Dec 2016 (and otherwise is `False`), and then group by that and a categorical race variable. This step produces a single dataframe for each time window--e.g., a dataframe for the 2-month bandwidth, a dataframe for the 4-month one, etc. \n",
    "4. Use `pd.concat` to combine those dataframes into a single dataframe.\n",
    "\n",
    "**Hint on output:** The table you make should have two Black-white disparities per bandwidth: one disparity (e.g., a 10 percentage point difference in incarceration rates) before the policy change and another disparity after (e.g., a 5 percentage point difference in incarceration rates). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5e1a9",
   "metadata": {},
   "source": [
    "### 2.2.4 Visualize the above (4 points)\n",
    "\n",
    "Use the table you just made to create a bar chart, where the x axis represents different bandwidths (2, 4, etc); the y axis the size of the Black-White gap, and for each of the x axis points, you have one shaded bar representing \"before\" the change, another representing \"after\" the change (make sure that before is ordered before after and the bandwidths are from smallest to largest)\n",
    "\n",
    "\n",
    "**Hints**: \n",
    "\n",
    "- For each of the bandwidths, include dates spanning the entire month: e.g., for the first, include not only 02-01-2017 but everything up through 02-28-2017; easiest way is for the subsetting to use the rounded `sentenceym_derived`. Also make sure to only include white or black defendants.\n",
    "\n",
    "- Depending on how you calculate/reshape things, you may find [this issue useful for how to collapse column names with a multilevel index](https://stackoverflow.com/questions/24290297/pandas-dataframe-with-multiindex-column-merge-levels) (also may not need it depending on how you structure the code).\n",
    "\n",
    "- The x-axis on the plot should be a categorical variable, with each of the bandwidths and with separate bars for before vs. after. If you want to change the order of the categories, [check out the `reorder_categories` function in this SO issue](https://stackoverflow.com/questions/38023881/pandas-change-the-order-of-levels-of-factor-type-object).\n",
    "\n",
    "**Extra credit** (1 point): because the bandwidths have different sample sizes, a better viz incorporates measures of uncertainty. Add standard errors to the points using the formula: $(\\dfrac{p(1-p)}{n})^{0.5}$ where N is the number of cases in each bandwidth period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe49c7a",
   "metadata": {},
   "source": [
    "### 2.2.5 Interpret the results (1 point)\n",
    "\n",
    "Write a two-sentence interpretation of the results. What might this show about how people on both sides of the issue---those arguing the policy change will narrow disparities; those arguing the change may widen disparities--could support their claims? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2a062",
   "metadata": {},
   "source": [
    "(your interpretation here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
