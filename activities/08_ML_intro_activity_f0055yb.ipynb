{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning: Introduction and regularization \n",
    "## Binary classification with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import pickle\n",
    "\n",
    "## nltk imports\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## random\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to process text\n",
    "def processtext(one_str, stop_list):\n",
    "    \n",
    "    ## remove stopwords\n",
    "    no_stop = [tok for tok in wordpunct_tokenize(one_str)\n",
    "              if tok not in stop_list]\n",
    "    \n",
    "    \n",
    "    processed_string = \" \".join([porter.stem(i.lower()) \n",
    "                        for i in no_stop if \n",
    "                        i.lower().isalpha() and len(i) >=3])\n",
    "    return(processed_string)\n",
    "\n",
    "## function to create dtm\n",
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names_out())\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Load labeled yelp data in `public_data` and run below code\n",
    "\n",
    "**Note**: make sure to change your path if you need to; if you're having trouble loading the `pkl`, try running on jupyter hub since it may be a python versioning issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have trouble loading these data (kernel dies due to memory issues), try sampling down to 5000 or 1000 rows\n",
    "yelp = pd.read_pickle(\"../public_data/yelp_forML.pkl\") #.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data to create dtm\n",
    "porter = PorterStemmer()\n",
    "list_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "yelp['process_text'] = [processtext(one_review, stop_list = list_stopwords) \n",
    "                        for one_review in yelp['raw_text']]\n",
    "\n",
    "yelp_dtm = create_dtm(yelp['process_text'], yelp[['metadata_label', 'metadata_rowid',\n",
    "                                                 'process_text', 'raw_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split into features, labels, and split into training/hold out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Split into X (features or id metadata) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_dtm[[col for col in yelp_dtm.columns if col not in ['metadata_label',\n",
    "                                                            'index']]].copy()\n",
    "y = yelp_dtm[['metadata_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 23439)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking dimensionality\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "assert X.shape[0] == y.shape[0]\n",
    "assert y.shape[1] == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 using automatic function to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using built-in function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 using more manual approach to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### more manually: useful when we want more control\n",
    "### over the ids (eg clustering or time ordering)\n",
    "### or if we want to go back to matrix before preprocessing\n",
    "nrows_train = round(X.shape[0]*0.8)\n",
    "nrows_test = X.shape[0] - nrows_train\n",
    "random.seed(221)\n",
    "train_ids = random.sample(list(set(X['metadata_rowid'])), nrows_train)\n",
    "\n",
    "def my_split(X, y, \n",
    "             train_ids, \n",
    "             id_col):\n",
    "    \n",
    "    ## get test ids\n",
    "    test_ids = set(X[id_col]).difference(train_ids)\n",
    "    \n",
    "    ## split\n",
    "    X_train_man = X[X[id_col].isin(train_ids)].copy()\n",
    "    X_test_man = X[X[id_col].isin(test_ids)].copy()\n",
    "    y_train_man = y[y.index.isin(train_ids)].iloc[:, 0].to_numpy()\n",
    "    y_test_man = y[y.index.isin(test_ids)].iloc[:, 0].to_numpy()\n",
    "    \n",
    "    ## return\n",
    "    return(X_train_man, X_test_man, y_train_man, y_test_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_man, X_test_man, y_train_man, y_test_man = my_split(X, y,\n",
    "                                                            train_ids, \n",
    "                                                            id_col = 'metadata_rowid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estimate models with hardcoded parameters: logistic regression with L1 regularization (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Estimate model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "non_feat = ['metadata_rowid', 'raw_text', 'process_text']\n",
    "logit_lasso = LogisticRegression(penalty = \"l1\",max_iter=100, \n",
    "             C = 0.01, solver='liblinear')\n",
    "logit_lasso.fit(X_train_man[[col for col in X_train.columns if col not in \n",
    "                   non_feat]], y_train_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate predictions in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit_lasso.predict(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "y_predprob = logit_lasso.predict_proba(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64278312, 0.35721688],\n",
       "       [0.69702331, 0.30297669],\n",
       "       [0.06368992, 0.93631008],\n",
       "       [0.72130534, 0.27869466],\n",
       "       [0.50400245, 0.49599755]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the results \n",
    "y_pred[0:5]\n",
    "y_predprob[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Clean up predictions and calculate error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0.240240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1</td>\n",
       "      <td>0.698195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.681838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>0</td>\n",
       "      <td>0.192977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_binary  y_pred_continuous  y_true\n",
       "656               0           0.240240       0\n",
       "825               1           0.698195       1\n",
       "1641              1           0.790555       1\n",
       "2249              1           0.535270       1\n",
       "1080              0           0.448153       0\n",
       "2490              0           0.432768       1\n",
       "2857              1           0.679604       1\n",
       "1160              1           0.681838       1\n",
       "1061              1           0.519535       0\n",
       "2255              0           0.192977       0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 22'. Pick better value with 'binwidth'.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (702558362)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make into a dataframe\n",
    "y_pred_df = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "y_pred_df.sample(n = 10, random_state = 4484)\n",
    "\n",
    "## plot prob versus true\n",
    "(ggplot(y_pred_df, aes(x = 'y_pred_continuous', group = 'factor(y_true)',\n",
    "                      fill = 'factor(y_true)')) +\n",
    "geom_histogram(alpha = 0.2, position = \"dodge\", color = 'black'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TN</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FP</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat     n\n",
       "0  TN  1320\n",
       "1  TP  1103\n",
       "2  FN   319\n",
       "3  FP   258"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8104335047759"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is:---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7756680731364276"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision as tp / tp+fp \n",
    "error_cond = [(y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 1),\n",
    "             (y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 0),\n",
    "              (y_pred_df['y_true'] == 0) & (y_pred_df['y_pred_binary'] == 0)]\n",
    "\n",
    "error_codeto = [\"TP\", \"FN\", \"TN\"]\n",
    "\n",
    "y_pred_df['error_cat'] = np.select(error_cond, error_codeto, default = \"FP\")\n",
    "y_error = y_pred_df.error_cat.value_counts().reset_index().copy()\n",
    "y_error.columns = ['cat', 'n']\n",
    "y_error\n",
    "\n",
    "### precision\n",
    "print(\"Precision is:-----------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FP\", 'n'].iloc[0])\n",
    "\n",
    "### recall\n",
    "print(\"Recall is:---------------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FN\", 'n'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Interpret the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>0.839766</td>\n",
       "      <td>delici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>0.780781</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>0.613979</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.444914</td>\n",
       "      <td>amaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>0.399658</td>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20768</th>\n",
       "      <td>-0.303461</td>\n",
       "      <td>terribl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21101</th>\n",
       "      <td>-0.309614</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>-0.362193</td>\n",
       "      <td>noth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>-0.381818</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>-0.488092</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef feature_name\n",
       "5009   0.839766       delici\n",
       "8170   0.780781        great\n",
       "11104  0.613979         love\n",
       "526    0.444914         amaz\n",
       "6510   0.399658        excel\n",
       "...         ...          ...\n",
       "20768 -0.303461      terribl\n",
       "21101 -0.309614         told\n",
       "14032 -0.362193         noth\n",
       "1251  -0.381818          bad\n",
       "23108 -0.488092        worst\n",
       "\n",
       "[23436 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delici</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>amaz</th>\n",
       "      <th>excel</th>\n",
       "      <th>best</th>\n",
       "      <th>favorit</th>\n",
       "      <th>friendli</th>\n",
       "      <th>definit</th>\n",
       "      <th>alway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026424</td>\n",
       "      <td>0.171178</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.113302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162248</td>\n",
       "      <td>0.557305</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.093621</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>0.116819</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.142640</td>\n",
       "      <td>0.242613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  delici     great      love      amaz     excel      best  \\\n",
       "metadata_label                                                               \n",
       "0               0.026424  0.171178  0.085976  0.022944  0.018819  0.103506   \n",
       "1               0.162248  0.557305  0.284452  0.104529  0.093621  0.219691   \n",
       "\n",
       "                 favorit  friendli   definit     alway  \n",
       "metadata_label                                          \n",
       "0               0.027713  0.067672  0.059036  0.113302  \n",
       "1               0.116819  0.169014  0.142640  0.242613  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get top features\n",
    "las_coef = pd.DataFrame({'coef': logit_lasso.coef_[0],\n",
    "                         'feature_name': \n",
    "                        [col for col in X_train.columns if col not in non_feat]})\n",
    "las_coef.sort_values(by = 'coef', ascending = False)\n",
    "\n",
    "\n",
    "top_feat = las_coef.sort_values(by = 'coef', ascending = False)[0:10]\n",
    "top_feat_list = top_feat.feature_name.to_list()\n",
    "\n",
    "all_agg = [yelp_dtm.groupby(['metadata_label']).agg({one_feat: np.mean})\n",
    "for one_feat in top_feat_list]\n",
    "all_agg_df = pd.concat(all_agg, axis = 1)\n",
    "all_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Live-coding: Compare performance across hyperparameters for logistic regression\n",
    "\n",
    "Would our logit model make more accurate predictions if we fed it different hyperpameters? Which hyperparameters would be the best? Let's find out.\n",
    "\n",
    "1. Define a function that:\n",
    "- takes in a cost parameter (*C*, the inverse of regularization strength)\n",
    "- trains a logistic regression model with L1 regularization (Lasso) and otherwise has the same parameters as above\n",
    "- fits the model on the training data\n",
    "- makes predictions and returns them as a DataFrame\n",
    "\n",
    "2. Use the function to get predictions for the list of *C* parameters below, then bind them into one DataFrame.\n",
    "\n",
    "3. Finally, score the precision for each model (each iteration of *C*) and show which model scores the best.\n",
    "\n",
    "**Hint**: To compute precision score, you can use:\n",
    "```python\n",
    "precision_score(\n",
    "    one_df['y_true'], one_df['y_pred'],\n",
    "    zero_division = 0) # silences warning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided set of hyperparameters on which to train and then compare performance\n",
    "c_list = np.linspace(4, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your function code here\n",
    "\n",
    "## Solution:\n",
    "## define function that takes in one cost parameter\n",
    "## and estimates model, returning pred\n",
    "def one_las(one_c):\n",
    "    one_lasso = LogisticRegression(penalty = \"l1\", max_iter=100, \n",
    "             C = one_c, solver='liblinear')\n",
    "    one_lasso.fit(X_train_man[[col for col in X_train.columns if \n",
    "                              col not in non_feat]], y_train_man)\n",
    "    y_pred = one_lasso.predict(X_test_man[[col for col in X_test_man.columns \n",
    "                if col not in non_feat]])\n",
    "    y_pred_df = pd.DataFrame({'y_pred': y_pred, \n",
    "                             'y_true': y_test_man,\n",
    "                             'cost': one_c})\n",
    "    return(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_pred  y_true  cost\n",
       "0       0       0   4.0\n",
       "1       0       0   4.0\n",
       "2       1       1   4.0\n",
       "3       0       0   4.0\n",
       "4       0       0   4.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.860594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000025</td>\n",
       "      <td>0.860977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000050</td>\n",
       "      <td>0.861687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000075</td>\n",
       "      <td>0.862543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cost  precision\n",
       "0  4.000000   0.860594\n",
       "1  3.000025   0.860977\n",
       "2  2.000050   0.861687\n",
       "3  1.000075   0.862543\n",
       "4  0.000100   0.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000075</td>\n",
       "      <td>0.862543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cost  precision\n",
       "3  1.000075   0.862543"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here to evaluate precision of each model\n",
    "\n",
    "## bind into one dataframe \n",
    "all_pred = [one_las(one_c) for one_c in c_list]\n",
    "all_pred_df = pd.concat(all_pred)\n",
    "all_pred_df.head()\n",
    "## score one cost level \n",
    "def score_onedf(one_c, all_c):\n",
    "    one_df = all_c[all_c.cost == one_c].copy()\n",
    "    prec_onec =  precision_score(\n",
    "        one_df['y_true'], one_df['y_pred'],\n",
    "        zero_division = 0)\n",
    "    return(prec_onec)\n",
    "    \n",
    "all_score = pd.DataFrame({'cost': c_list,\n",
    "                          'precision': [score_onedf(one_c, all_pred_df) \n",
    "                                  for one_c in c_list]})\n",
    "all_score\n",
    "\n",
    "all_score[all_score.precision == np.max(all_score.precision)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Activity \n",
    "\n",
    "- Read the documentation here to initialize a ridge regression (l2 penalty)- you can use the same cost parameter (C) and number of iterations as in the lasso example above: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- Fit the model on X_train_man, y_train_main \n",
    "- Generate binary and continuous predictions\n",
    "- Create a function that takes in a dataframe of binary predictions and true labels and manually calculates the $F_{1}$ score:\n",
    "\n",
    "$$F_{1} = 2 * \\dfrac{precision * recall}{precision + recall} = \\dfrac{TP}{TP + 0.5(FP + FN)}$$\n",
    "\n",
    "- Apply that function to calculate the F1 score for the decision tree and lasso (from above), and ridge regression (from the activity)\n",
    "- *Challenge exercise*: parametrize the model fitting with a function that takes in a classifier as an argument and returns coefficients or feature importances and certain eval metrics (eg precision, recall, and F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, solver='liblinear')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here \n",
    "ridge = LogisticRegression(penalty = \"l2\",max_iter=100, \n",
    "             C = 1, solver='liblinear')\n",
    "\n",
    "X_feat_train = X_train_man[[col for col in X_train_man.columns \n",
    "                if col not in non_feat]]\n",
    "X_feat_test = X_test_man[[col for col in X_test_man.columns \n",
    "                if col not in non_feat]]\n",
    "\n",
    "ridge.fit(X_feat_train, y_train_man)\n",
    "\n",
    "y_pred = ridge.predict(X_feat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra challenge\n",
    "\n",
    "Text vectorization methods affect downstream classification accuracy. Above, we used simple term counts to turn texts into numbers. This time, instead of using term frequencies, use `sklearn`'s `TfidfVectorizer()` function to weight features with term frequency inverse document frequency (TF-IDF): this gives a word greater weight both when it is more frequent in a text AND when it is rare across the corpus. Does this vectorization approach improve classification accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
